{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a41f2011-b934-41b8-bbd7-6434d4162834",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Predicting the results of football matches is an area of active research, with state of the art models reaching accuracies of only about 50\\%. â€ŒIn this paper, additional data to model the performance of each football club - e.g. club worth, attack score, etc. - was sourced, and an exponential weighted average calculated from them in order to model time decay in the style of the Dixon-Coles model of modelling goal likelihood. Some dimensionality reduction was also attempted on the feature set using Linear Discriminant Analysis with little effect. The resulting data was then tested with a repertoire of five different classifier models, all of which achieved accuracies of between 0.468 and 0.534. Of these, a Support Vector Machine was chosen as it consistently demonstrated the highest accuracy. Lastly, sequential feature selection, where features are added and removed to determine their effect on accuracy, demonstrated that accuracy peaked when three features where being considered at once. The cross validation of the model was calculated to be 0.55 with a standard deviation of 0.014. In terms of predictions using training data, it was noticed that the feature which was correctly predicted with the highest accuracy of 0.78 was home wins whereas probability of away wins being correctly predicted was 0.56. Interestingly, the model made no predictions for draws, with the probability of incorrectly predicting a draw as home win being 22\\% higher than predicting it as an away win."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b0ae23-e3fb-4f3a-b956-564d408390ae",
   "metadata": {},
   "source": [
    "# Data Import\n",
    "\n",
    "The section imports all the required libraries. Then, the required CSV files are loaded into variables for use throughout the notebook. There are three required CSV files.\n",
    "\n",
    "`epi-training.csv` - contains the provided match data\n",
    "\n",
    "`epl-teams.csv` - contains scraped team scores from [sofifa.com](https://sofifa.com)\n",
    "\n",
    "`epl-test.csv` - contains the final test data\n",
    "\n",
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e73e652-4b4b-4575-9856-3614f79a65cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf128e7-aae4-4386-876f-a9f2f9ec86e4",
   "metadata": {},
   "source": [
    "## Scraping tool\n",
    "\n",
    "The scraping tool is stored in a separate python file, `fifa_scraper.py`. If the `epl-teams.csv` has not been generated, the scraper must be run. Configure the leagues for which to retrieve team scores by controlling the years variable, each year has a corresponding league ID which can be found on [sofifa.com](sofifa.com).\n",
    "\n",
    "The team scores that are obtained are ratings from FIFA, which represent a measure of how popular and good each team is considered to be. This can be used to augment the training data.\n",
    "\n",
    "The following ratings are collected\n",
    "\n",
    "- **OA**: Overall score (0-100)\n",
    "- **AT**: Attack score (0-100)\n",
    "- **MD**: Midfield score (0-100)\n",
    "- **DF**: Defense score (0-100)\n",
    "- **CW**: Club worth (millions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc59d05-6ac8-4236-b7ee-5c7d17295fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fifa_scraper import scrape_premier_league_teams\n",
    "\n",
    "years = [('240016', 2024), ('230054', 2023), ('220069', 2022), \n",
    "         ('210064', 2021), ('200061', 2020), ('190075', 2019), \n",
    "         ('180084', 2018), ('170099', 2017), ('160058', 2016), \n",
    "         ('150059', 2015), ('140052', 2014), ('130034', 2013)]\n",
    "\n",
    "scrape_premier_league_teams(years)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7759cde1-fbc0-4a64-b9b9-f30029333370",
   "metadata": {},
   "source": [
    "## Data loading\n",
    "\n",
    "Now, processing and loading all the required data. The match data is stored in `df` and the team scores are stored in `df_teams`. In following sections, the two features will be merged. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0c7f17-c0d2-4a99-a931-e74c93921552",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = './' # ENTER YOUR WORKING DRIECTORY HERE #\n",
    "epl_training_path = root_dir + 'epl-training.csv'\n",
    "epl_teams_path = root_dir + 'epl-teams.csv'\n",
    "epl_test_path = root_dir + 'epl-test.csv'\n",
    "\n",
    "# Load and describe the csv file\n",
    "df = pd.read_csv(epl_training_path)\n",
    "df_teams = pd.read_csv(epl_teams_path)\n",
    "df_test = pd.read_csv(epl_test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdc2ca4-2c36-424e-8ed5-61ff508bee93",
   "metadata": {},
   "source": [
    "### _Raw Training Data_\n",
    "View the match data and verify content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e326f1e8-9c55-4273-8846-212ced3a317e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8b059a-7260-40ad-ae7b-4e242bbda65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ce090e-68bc-426e-8c5d-3c9ad088b35a",
   "metadata": {},
   "source": [
    "### _Raw Team Scores_\n",
    "View the raw team scores and verify content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513f98a5-7a96-4124-9172-648cc45adf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teams.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54292956-da2a-4970-bc5e-5f350c01504e",
   "metadata": {},
   "source": [
    "# Data Transformation and Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca8e82e-fb0f-4d24-90f7-c5ae1eeb6fe2",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "The section double checks the match data stored in `df` for any missing values and NaNs which might generate problems later on. All rows with NaN values are dropped.\n",
    "\n",
    "`df_teams` need not be sanitized as it is sanitized by the scraper tool during the scraping process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b95516-4aed-4834-aa05-88f0b1737ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any row where the HomeTeam or AwayTeam is not a valid name\n",
    "df = df.dropna()\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Check that all invalid fields have been removed\n",
    "assert(df['HomeTeam'].apply(lambda x: not isinstance(x, str)).sum() == 0)\n",
    "assert(df['AwayTeam'].apply(lambda x: not isinstance(x, str)).sum() == 0)\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad0d6ae-c79a-4106-8e6a-8d56c0b203be",
   "metadata": {},
   "source": [
    "This results in roughly half of the match data being discarded. However, 4082 matchs is sufficient examples for the model to achieve good performance.\n",
    "\n",
    "## Encoding classes as labels\n",
    "\n",
    "To encode classes as labels, the `LabelEncoder` from sklearn is used. There are two primary pieces of class information, namely the team names and the final result. The team names in `df_teams` is already standardized with the names used in the match data, thus the same `LabelEncoder` can be used in both cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b623c2-dceb-4e0a-8ca9-4d15f3df7377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate LabelEncoder\n",
    "team_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the 'Names' column with LabelEncoder\n",
    "team_encoder = team_encoder.fit(df['HomeTeam'])\n",
    "df['HomeTeamLabel'] = team_encoder.transform(df['HomeTeam'])\n",
    "df['AwayTeamLabel'] = team_encoder.transform(df['AwayTeam'])\n",
    "df_teams['TeamLabel'] = team_encoder.transform(df_teams['Team'])\n",
    "\n",
    "print(f\"Team Names: {team_encoder.classes_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c58b8d5-1e89-42a8-ac5e-d116da72badc",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_encoder = LabelEncoder()\n",
    "result_encoder = result_encoder.fit(df['FTR'])\n",
    "df['FTRLabel'] = result_encoder.transform(df['FTR'])\n",
    "df['HTRLabel'] = result_encoder.transform(df['HTR'])\n",
    "\n",
    "print(f\"Result names: {result_encoder.classes_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28535ff-b6f3-4cde-92c5-a5953dc8ceb2",
   "metadata": {},
   "source": [
    "## Analyzing home team advantage\n",
    "\n",
    "Looking at the data, it is possible to calculate the probability of a home team winning, against the away team winning, against a draw. It is clear that the home team is more likely to win as compared to the away team, showing the existence of home team advantage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaaf593e-7679-4fae-9bb6-225ece5be449",
   "metadata": {},
   "outputs": [],
   "source": [
    "ftr_counts = df['FTR'].value_counts(normalize=True) # Normalize to convert to probabilities\n",
    "\n",
    "print(ftr_counts)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "ftr_counts.plot(kind='bar', edgecolor='black')\n",
    "plt.xlabel('Game Outcome')\n",
    "plt.ylabel('Probability')\n",
    "plt.xticks(range(len(ftr_counts)), ['Home Win', 'Away Win', 'Draw'], rotation=0)\n",
    "plt.grid(axis='y')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513aa557-8a59-4c5d-b03c-de098a29e308",
   "metadata": {},
   "source": [
    "## Combined match data and team scores\n",
    "\n",
    "The following snippet of code combines the data from each match and the team scores. While doing so, it performs data transformation on the match data to make it more suitable for future training.\n",
    "\n",
    "### _Feature engineering from match data_\n",
    "\n",
    "One concern with the match data in its current form, is that a process must be developed to rollup historical match data into a feature vector which can be used to classify the next result. A naive implementation might just use the features of the immediately preceeding home and away game, but a better approach would include the historial data of the team.\n",
    "\n",
    "The **Dixon-Coles model**, uses a poisson distribution to model the goal likelihood of the home and away teams, to make predictions on game outcomes. Two key contributions the model made to the basic possion model is to add a correction term for low-frequency matches (games with 0-0, 0-1, 1-0, and 1-1) outcomes, and to add a exponential time weighting component to more strongly consider recent matches than old matches.\n",
    "\n",
    "The second element is of concern to use in the feature engineering stage. By applying an exponential weighted average to columns, a feature can be constructed for each column in the match data. The features can be precomputed like follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb28e3e-39ff-4283-9c89-ee0e0d0b41a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_columns = ['FTHG', 'HTHG', 'HS', 'HST', 'HF', 'HC', 'HY', 'HR']\n",
    "away_columns = ['FTAG', 'HTAG', 'AS', 'AST', 'AF', 'AC', 'AY', 'AR']\n",
    "team_columns_single = ['OA', 'AT', 'MD', 'DF', 'CW']\n",
    "team_columns = ['HOA', 'HAT', 'HMD', 'HDF', 'HCW', 'AOA', 'AAT', 'AMD', 'ADF', 'ACW']\n",
    "\n",
    "td = pd.Timedelta(days=365) # Adjust for exponential weighting\n",
    "\n",
    "# Precomputing features\n",
    "precomputed_features = {}\n",
    "\n",
    "for team in team_encoder.classes_:\n",
    "    #  Calculating the Home features\n",
    "    df_home = df[df['HomeTeam'] == team]\n",
    "    df_home = df_home[['Date', *home_columns]]\n",
    "\n",
    "    # Applying the exponential weighting mean\n",
    "    df_home[home_columns] = df_home[home_columns].ewm(times=df_home['Date'], halflife=td).mean()\n",
    "    precomputed_features[team] = {}\n",
    "    precomputed_features[team]['Home'] = df_home\n",
    "    \n",
    "    # Calculating the Away features\n",
    "    df_away = df[df['AwayTeam'] == team]\n",
    "    df_away = df_away[['Date', *away_columns]]\n",
    "\n",
    "    # Applying the exponential weighting mean\n",
    "    df_away[away_columns] = df_away[away_columns].ewm(times=df_away['Date'], halflife=td).mean()\n",
    "    precomputed_features[team]['Away'] = df_away\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86e375b-964a-4d8d-a454-355ab328736c",
   "metadata": {},
   "source": [
    "### _Merging match data with team scores_\n",
    "\n",
    "To construct the final feature matrix, the transformed match data must be merged with the team scores. For each match, a feature is constructed by taking the exponential weighted mean up to the previous match, and the home and away team scores for that league is appended to the feature.\n",
    "\n",
    "Additionally, only match data after 2013 is considered useful, as a decade of training examples is deemed to be sufficient to minimize bias in predictions. Too much match data might confuse the model with players in teams which do not play anymore.\n",
    "\n",
    "The team scores are assumed to be constant throughout a league."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cc7a6c-46fb-48c9-be0c-ea251b1da8ad",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List to store league date ranges\n",
    "league_dates = []\n",
    "\n",
    "# Loop through the years from 2014 to 2023. \n",
    "for year in range(2013, 2023 + 1):\n",
    "    # Define the start and end dates for each league year (assuming August 1 to June 1)\n",
    "    start_date = f\"{year}-08-01\"\n",
    "    end_date = f\"{year + 1}-06-01\"\n",
    "    \n",
    "    # Append the start and end dates as a tuple to the league_dates list\n",
    "    league_dates.append((start_date, end_date, year))\n",
    "\n",
    "feature_columns = ['Date', 'League', 'HomeTeam', 'AwayTeam', *home_columns, *away_columns, *team_columns, 'FTRLabel']\n",
    "df_features = pd.DataFrame(columns=feature_columns)\n",
    "feature_list = []\n",
    "\n",
    "for start, end, year in league_dates:\n",
    "    print(f\"{start} : {end}\")\n",
    "    league = df[(df['Date'] >= start) & (df['Date'] <= end)]\n",
    "    \n",
    "    for index in range(len(league)):\n",
    "        row = league.iloc[index]\n",
    "        home =  precomputed_features[row['HomeTeam']]['Home']\n",
    "        home = home[home['Date'] < row['Date']]\n",
    "        if home.empty:\n",
    "            continue\n",
    "        else:\n",
    "            home = home.iloc[-1]\n",
    "\n",
    "        # Check if ratings exist for the year\n",
    "        home_team = df_teams[df_teams['Team'] == row['HomeTeam']]\n",
    "        home_team = home_team[home_team['Year'] == year]\n",
    "\n",
    "        # Else use the latest one\n",
    "        if home_team.empty:\n",
    "            home_team = df_teams[df_teams['Team'] == row['HomeTeam']]\n",
    "            home_team = home_team[home_team['Year'] < year]\n",
    "            # Else use sensible default team stats\n",
    "            if home_team.empty:\n",
    "                home_team = pd.DataFrame([[60, 60, 60, 60, 1]], columns=team_columns_single) # Defaults\n",
    "                home_team = home_team.iloc[0]\n",
    "            else:\n",
    "                home_team = home_team.iloc[0]\n",
    "        else:\n",
    "            home_team = home_team.iloc[0]\n",
    "\n",
    "        away =  precomputed_features[row['AwayTeam']]['Away']\n",
    "        away = away[away['Date'] < row['Date']]\n",
    "        if away.empty:\n",
    "            continue\n",
    "        else:\n",
    "            away = away.iloc[-1]\n",
    "\n",
    "        # Check if ratings exist for the year\n",
    "        away_team = df_teams[df_teams['Team'] == row['AwayTeam']]\n",
    "        away_team = away_team[away_team['Year'] == year]\n",
    "\n",
    "        # Else use the latest one\n",
    "        if away_team.empty:\n",
    "            away_team = df_teams[df_teams['Team'] == row['AwayTeam']]\n",
    "            away_team = away_team[away_team['Year'] < year]\n",
    "            if away_team.empty:\n",
    "                # Else use sensible default team stats\n",
    "                away_team = pd.DataFrame([[60, 60, 60, 60, 1]], columns=team_columns_single) # Defaults\n",
    "                away_team = away_team.iloc[0]\n",
    "            else:\n",
    "                away_team = away_team.iloc[0]\n",
    "        else:\n",
    "            away_team = away_team.iloc[0]\n",
    "\n",
    "        feature_list.append([row['Date'], year, row['HomeTeam'], row['AwayTeam'],\n",
    "                            *home[home_columns], *away[away_columns],\n",
    "                            *home_team[team_columns_single], *away_team[team_columns_single], row['FTRLabel']])\n",
    "\n",
    "df_features = pd.DataFrame(feature_list, columns=feature_columns)\n",
    "df_features.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28ec59a-b890-403b-817f-4ebfb96cb08f",
   "metadata": {},
   "source": [
    "## Plot the correlation matrix\n",
    "\n",
    "It is unsurprising if many of the features in the augmented feature set are redundant, as many factors of matches are correlated. For example, the Half Time goals is correlated to the full time goals for both the home and away team. It is worth getting an idea of which features are correlated to which other features to aid in feature selection, and to help preserve conditional probability assumptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd3ac19-fd6e-483a-8350-be9ebfb85f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_mat = df_features[[*home_columns, *away_columns, *team_columns]].corr().stack().reset_index(name=\"correlation\")\n",
    "\n",
    "# Draw each cell as a scatter point with varying size and color\n",
    "g = sns.relplot(\n",
    "    data=corr_mat,\n",
    "    x=\"level_0\", y=\"level_1\", hue=\"correlation\", size=\"correlation\",\n",
    "    palette=\"vlag\", hue_norm=(-1, 1), edgecolor=\".7\",\n",
    "    height=10, sizes=(50, 250), size_norm=(-.2, .8),\n",
    ")\n",
    "\n",
    "# Tweak the figure to finalize\n",
    "g.set(xlabel=\"\", ylabel=\"\", aspect=\"equal\")\n",
    "g.despine(left=True, bottom=True)\n",
    "g.ax.margins(.02)\n",
    "for label in g.ax.get_xticklabels():\n",
    "    label.set_rotation(90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27bfc62-1071-42f5-b9dc-5cfd3223a70d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Methodology Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a3bcb0-1cc6-4b7b-8b89-6081b7dfda05",
   "metadata": {},
   "source": [
    "## Train-test split\n",
    "\n",
    "The performance of teams in leagues is expected to vary through the duration of a league. This could be due to tiredness, loss of morale and other factors. Therefore, the performance of any model could vary significantly during a league.\n",
    "\n",
    "Thus, the test setup of models must consider this fact, and entire leagues must be set aside for testing. In this study, the years 2013-2019, are considered training data and 2020 onwards is considered test data. Within the training data, **5-fold cross validation** shall be used for hyperparameter tuning. The data is split as follows.\n",
    "\n",
    "- Training Set: 2462 matches (67.8%)\n",
    "- Test Set: 1170 matches (32.2%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fe77a4-cb61-49c7-943c-7c9c3e3f3d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_train = df_features[df_features['League'] <= 2019] # Train on everything before and including 2019\n",
    "df_features_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d47a83-ad71-4b21-85a1-573e44147a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_test = df_features[df_features['League'] > 2019] # Test on 2019 and onwards\n",
    "df_features_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d7c077-1f1f-405a-907e-6304adf45b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_features_train[[*home_columns, *away_columns, *team_columns]].values\n",
    "y_train = df_features_train[['FTRLabel']].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0363a310-7c14-4d19-b67f-dc036a34c942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply LDA with 2 components for visualization (can be changed)\n",
    "lda = LDA(n_components=2)\n",
    "X_lda = lda.fit_transform(X_train, y_train)\n",
    "\n",
    "targets = list(set(y_train))\n",
    "colors = ['blue', 'orange', 'green']\n",
    "\n",
    "for target, color in zip(targets, colors):\n",
    "    indices_to_keep = y_train == target\n",
    "    plt.scatter(X_lda[indices_to_keep, 0], X_lda[indices_to_keep, 1], c=color, label=target, edgecolor='k')\n",
    "\n",
    "plt.xlabel('Linear Discriminant 1')\n",
    "plt.ylabel('Linear Discriminant 2')\n",
    "plt.title('LDA of features')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49812f0a-b032-4173-9fc5-d7d7e204d6c9",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "\n",
    "There are a variety of possible models that could be deployed for this problem. The following section attempts to compare different models and their performance for the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cd3b14-d0da-4bb8-b1c9-d8471ef1c67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_compare_classifiers(X, y, classifiers, title=\"Comparison of Classifier Accuracies\"):\n",
    "    accuracies = {}\n",
    "    std_devs = {}\n",
    "    \n",
    "    for clf_name, clf in classifiers.items():\n",
    "        skf = StratifiedKFold(n_splits=5)\n",
    "        scores = cross_val_score(clf, X, y, cv=skf)\n",
    "        accuracies[clf_name] = scores.mean()\n",
    "        std_devs[clf_name] = scores.std()\n",
    "\n",
    "        print(f\"{clf_name}: Mean {scores.mean()}, Std. Deviation {scores.std()}\")\n",
    "\n",
    "    # Plotting accuracies\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(accuracies.keys(), accuracies.values(), yerr=list(std_devs.values()), capsize=5, alpha=0.7)\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title(title)\n",
    "    plt.ylim([0, 1])\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Add labels on top of each bar\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        label = height * 100\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, height + 0.05, f'{label:.3f}%', ha='center', va='bottom')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2006a799-e0fa-4a92-9c21-b5803c1e89aa",
   "metadata": {},
   "source": [
    "### _Setup 5 potential classifier types_\n",
    "\n",
    "For all classifier types, having a normalization applied to the features tends to prevent a single feature from dominating the loss function classifier. Thus a `StandardScaler` is applied to the data within a Pipeline, to normalize the data.\n",
    "\n",
    "The tested classifiers are: Support Vector Machine, KNN, Random Forest, Naive Bayes and Logistic Regression. Of these, the Support Vector Machine has the best empirical performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e12d02-a35d-45c0-829b-d4352eadbe55",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    'SVM': Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('classifier', SVC())]),\n",
    "    'KNN': Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('classifier', KNeighborsClassifier())]),\n",
    "    'Random Forest': Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('classifier', RandomForestClassifier())]),\n",
    "    'Naive Bayes': Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('classifier', GaussianNB())]),\n",
    "    'Logistic Regression': Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('classifier', LogisticRegression())]),\n",
    "}\n",
    "\n",
    "train_and_compare_classifiers(X_train, y_train, classifiers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafb823e-5190-4579-a4f8-6d97f92f8cd3",
   "metadata": {},
   "source": [
    "### _Dimensionality Reduction_\n",
    "Since there are many features, and many of those features are correlated, there might be opportunites where dimensionality reduction could improve the performance of the model. Since the Logistic Regression is seen to have the best classifier performance, it is chosen for further investigation.\n",
    "\n",
    "A standard `LogisticRegression` is compared to an `LogisticRegression` with Principal Component Analysis appled, and another with Linear Discriminant Analysis applied, as a preprocessing step. A `Pipeline` is used to prevent data leakage.\n",
    "\n",
    "Dimensionality reduction does not help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af4009b-dd1d-4f0a-a3e6-f5e3dfedf5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    'SVM': Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('classifier', SVC())]),\n",
    "    'SVM + PCA': Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('pca', PCA(n_components=2)), # There are only 3 classes\n",
    "            ('classifier', SVC())]),\n",
    "    'SVM + LDA': Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('lda', LDA(n_components=2)),\n",
    "            ('classifier', SVC())]),\n",
    "}\n",
    "\n",
    "train_and_compare_classifiers(X_train, y_train, classifiers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401eaac9-f97a-4b00-b985-9080f29343d9",
   "metadata": {},
   "source": [
    "### _Hyperparameter Tuning_\n",
    "\n",
    "This section looks at the SVC C hyperparameter, to see if hyperparameter tuning can help outperform the Logistic Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bcfd82-79ba-4ccc-b352-400af416581b",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    'SVM (C=0.001)': Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('classifier', SVC(C=0.001))]),\n",
    "    'SVM (C=0.01)': Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('classifier', SVC(C=0.01))]),\n",
    "    'SVM (C=0.1)': Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('classifier', SVC(C=0.1))]),\n",
    "    'SVM (C=1.0)': Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('classifier', SVC(C=1.0))]),\n",
    "    'SVM (C=10)': Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('classifier', SVC(C=10))]),\n",
    "     'SVM (C=100)': Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('classifier', SVC(C=100))]),\n",
    "    'SVM (C=1000)': Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('classifier', SVC(C=1000))])\n",
    "}\n",
    "\n",
    "train_and_compare_classifiers(X_train, y_train, classifiers, title=\"Hyperparameter tuning for SVM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a232987-699d-4586-9d69-da838cb80be2",
   "metadata": {},
   "source": [
    "### _Sequential Feature Selection_\n",
    "Since there are still many correlated features, and dimensionality reduction did not help, sequential feature selection is used to find optimal features to include. Mean validation accuracy peaks at **7 features**, and the 7 selected features are used in the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d685786c-1db7-4e46-a6fe-3bc40153ac94",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('classifier', SVC(C=1.0))])\n",
    "\n",
    "accuracies = {}\n",
    "std_devs = {}\n",
    "\n",
    "for i in range(1, 11):\n",
    "    sfs_forward = SequentialFeatureSelector(\n",
    "        clf, n_features_to_select=i, direction=\"forward\", n_jobs=4\n",
    "    ).fit(X_train, y_train)\n",
    "\n",
    "    selected_features = sfs_forward.get_support()\n",
    "    X_train_selected = X_train[:, selected_features]\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5)\n",
    "    scores = cross_val_score(clf, X_train_selected, y_train, cv=skf)\n",
    "    accuracies[f\"{i}\"] = scores.mean()\n",
    "    std_devs[f\"{i}\"] = scores.std()\n",
    "\n",
    "    print(f\"Using {i} features, mean score: {scores.mean()}, std dev: {scores.std()}\")\n",
    "\n",
    "# Plotting accuracies\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(accuracies.keys(), accuracies.values(), yerr=list(std_devs.values()), capsize=5, alpha=0.7)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of Selected Features')\n",
    "plt.title('Feature Selection with SVM')\n",
    "plt.ylim([0.5, 0.6])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Add labels on top of each bar\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, height, f'{height:.3f}', ha='center', va='bottom')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b8feab-f4d1-447b-83d4-2bc199cc0a36",
   "metadata": {},
   "source": [
    "# Model Training and Validation\n",
    "\n",
    "In the full training run, the following setup will be used.\n",
    "\n",
    "* The training data will be all the data until the **2019** league.\n",
    "* The test data will be the **2020** league and onwards.\n",
    "* Forward Sequential Feature Selection will be done to identify the top 10 features for the model.\n",
    "* All features will be scaled to zero mean and unit variance\n",
    "* A logistic regression classifier will be used as the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4951eb2-1546-4321-bedd-a434467db3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_features_train[[*home_columns, *away_columns, *team_columns]].values\n",
    "y_train = df_features_train[['FTRLabel']].values.ravel()\n",
    "\n",
    "X_test = df_features_test[[*home_columns, *away_columns, *team_columns]].values\n",
    "y_test = df_features_test[['FTRLabel']].values.ravel()\n",
    "\n",
    "print(f\"Training set size is {X_train.shape}\")\n",
    "print(f\"Test set size is {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1b40cc-a094-4e5c-89c8-f847d9a35408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pipeline\n",
    "clf = Pipeline([('scaler', StandardScaler()), ('classifier', SVC(C=1.0))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93db8a8-ad56-4948-8838-b79e493292f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential Feature Selection, select 10\n",
    "sfs_forward = SequentialFeatureSelector(\n",
    "    clf, n_features_to_select=10, direction=\"forward\", n_jobs=4\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "selected_features = sfs_forward.get_support()\n",
    "X_train_selected = X_train[:, selected_features]\n",
    "\n",
    "feature_names = np.array([*home_columns, *away_columns, *team_columns])\n",
    "selected_feature_names = feature_names[selected_features]\n",
    "print(f\"The selected features are {selected_feature_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e17f20-2f82-406a-a599-bd438cfad13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_features_train[selected_feature_names].values\n",
    "y_train = df_features_train[['FTRLabel']].values.ravel()\n",
    "\n",
    "X_test = df_features_test[selected_feature_names].values\n",
    "y_test = df_features_test[['FTRLabel']].values.ravel()\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=skf)\n",
    "print(f\"Cross validation accuracy of the pipeline is {scores.mean()}. Std dev: {scores.std()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc5cbcf-09a0-4ed5-897b-068992cfc48c",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825a1739-2a6a-469b-beb5-38adeb2c2a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score = clf.fit(X_train, y_train).score(X_test, y_test)\n",
    "print(f\"Test accuracy of the pipeline is {test_score}\")\n",
    "\n",
    "disp = ConfusionMatrixDisplay.from_estimator(\n",
    "    clf,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    display_labels=result_encoder.classes_,\n",
    "    normalize=\"true\",\n",
    ")\n",
    "print(disp.confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c34e67-39fc-4c39-b46b-72cfd6d2f3f3",
   "metadata": {},
   "source": [
    "# Final Predictions on Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc04954-9a51-4daf-820f-81a7e460f70b",
   "metadata": {},
   "source": [
    "## Generate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108f83ed-243f-4343-9062-6df95985f94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup variables to store the computed features\n",
    "test_feature_list = []\n",
    "test_feature_columns = ['Date', 'League', 'HomeTeam', 'AwayTeam', *home_columns, *away_columns, *team_columns]\n",
    "\n",
    "# Name map because test team names are different from training team names\n",
    "name_map = {\n",
    "    'Man City': 'Man City',\n",
    "    'Arsenal': 'Arsenal',\n",
    "    'Liverpool': 'Liverpool',\n",
    "    'Man Utd': 'Man United',\n",
    "    'Spurs': 'Tottenham',\n",
    "    'Aston Villa': 'Aston Villa',\n",
    "    'Chelsea': 'Chelsea',\n",
    "    'Newcastle': 'Newcastle',\n",
    "    'West Ham': 'West Ham',\n",
    "    'Everton': 'Everton',\n",
    "    'Nottingham Forest': \"Nott'm Forest\",\n",
    "    'Brighton': 'Brighton',\n",
    "    'Wolves': 'Wolves',\n",
    "    'Fulham': 'Fulham',\n",
    "    'Crystal Palace': 'Crystal Palace',\n",
    "    'Brentford': 'Brentford',\n",
    "    'AFC Bournemouth': 'Bournemouth',\n",
    "    'Burnley': 'Burnley',\n",
    "    'Cardiff City': 'Cardiff',\n",
    "    'Huddersfield Town': 'Huddersfield',\n",
    "    'Hull City': 'Hull',\n",
    "    'Leeds United': 'Leeds',\n",
    "    'Leicester City': 'Leicester',\n",
    "    'Luton Town': 'Luton',\n",
    "    'Middlesbrough': 'Middlesbrough',\n",
    "    'Norwich City': 'Norwich',\n",
    "    'Queens Park Rangers': 'QPR',\n",
    "    'Reading': 'Reading',\n",
    "    'Sheff Utd': 'Sheffield United',\n",
    "    'Southampton': 'Southampton',\n",
    "    'Stoke City': 'Stoke',\n",
    "    'Sunderland': 'Sunderland',\n",
    "    'Swansea City': 'Swansea',\n",
    "    'Watford': 'Watford',\n",
    "    'West Bromwich Albion': 'West Brom',\n",
    "    'Wigan Athletic': 'Wigan'\n",
    "}\n",
    "\n",
    "for index in range(len(df_test)):\n",
    "    year = 2024\n",
    "    row = df_test.iloc[index]\n",
    "    hometeam = name_map[row['HomeTeam']]\n",
    "    awayteam = name_map[row['AwayTeam']]\n",
    "    \n",
    "    home =  precomputed_features[hometeam]['Home']\n",
    "    home = home[home['Date'] < row['Date']]\n",
    "    if home.empty:\n",
    "        continue\n",
    "    else:\n",
    "        home = home.iloc[-1]\n",
    "\n",
    "    # Check if ratings exist for the year\n",
    "    home_team = df_teams[df_teams['Team'] == hometeam]\n",
    "    home_team = home_team[home_team['Year'] == year]\n",
    "\n",
    "    # Else use the latest one\n",
    "    if home_team.empty:\n",
    "        home_team = df_teams[df_teams['Team'] == hometeam]\n",
    "        home_team = home_team[home_team['Year'] < year]\n",
    "        # Else use sensible default team stats\n",
    "        if home_team.empty:\n",
    "            home_team = pd.DataFrame([[60, 60, 60, 60, 1]], columns=team_columns_single) # Defaults\n",
    "            home_team = home_team.iloc[0]\n",
    "        else:\n",
    "            home_team = home_team.iloc[0]\n",
    "    else:\n",
    "        home_team = home_team.iloc[0]\n",
    "\n",
    "    away =  precomputed_features[awayteam]['Away']\n",
    "    away = away[away['Date'] < row['Date']]\n",
    "    if away.empty:\n",
    "        continue\n",
    "    else:\n",
    "        away = away.iloc[-1]\n",
    "\n",
    "    # Check if ratings exist for the year\n",
    "    away_team = df_teams[df_teams['Team'] == awayteam]\n",
    "    away_team = away_team[away_team['Year'] == year]\n",
    "\n",
    "    # Else use the latest one\n",
    "    if away_team.empty:\n",
    "        away_team = df_teams[df_teams['Team'] == awayteam]\n",
    "        away_team = away_team[away_team['Year'] < year]\n",
    "        if away_team.empty:\n",
    "            # Else use sensible default team stats\n",
    "            away_team = pd.DataFrame([[60, 60, 60, 60, 1]], columns=team_columns_single) # Defaults\n",
    "            away_team = away_team.iloc[0]\n",
    "        else:\n",
    "            away_team = away_team.iloc[0]\n",
    "    else:\n",
    "        away_team = away_team.iloc[0]\n",
    "\n",
    "    test_feature_list.append([row['Date'], year, hometeam, awayteam,\n",
    "                        *home[home_columns], *away[away_columns],\n",
    "                        *home_team[team_columns_single], *away_team[team_columns_single]])\n",
    "\n",
    "test_df_features = pd.DataFrame(test_feature_list, columns=test_feature_columns)\n",
    "test_df_features.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046272c0-7574-4fcc-b238-34a67d171046",
   "metadata": {},
   "source": [
    "## Train on all the data and make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3ae389-d72b-45ff-a67e-50c439d967e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use selected features from earlier\n",
    "X = df_features[selected_feature_names].values\n",
    "y = df_features[['FTRLabel']].values.ravel()\n",
    "\n",
    "X_test = test_df_features[selected_feature_names].values\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', SVM(C=1.0))\n",
    "])\n",
    "\n",
    "y_pred = pipeline.fit(X,y).predict(X_test)\n",
    "y_pred = result_encoder.inverse_transform(y_pred)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8356358f-71c0-46b7-9ede-02a9f343bc14",
   "metadata": {},
   "source": [
    "## Store to the csv in desired format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1ac323-40f0-4731-ad1b-35905afba958",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['FTR'] = y_pred\n",
    "df_test.to_csv('epl-test-populated.csv', index=False)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc4af41-5df2-4410-b311-098fe2396e95",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9ccab6-3799-420f-954d-d637eeaec43a",
   "metadata": {},
   "source": [
    "- [Forecasting football](https://mercurius.io/en/learn/predicting-forecasting-football)\n",
    "- [Prediction of football match results with Machine Learning](https://www.sciencedirect.com/science/article/pii/S1877050922007955)\n",
    "- [Predicting Football Matches Results using Bayesian Networks for English Premier League (EPL)](https://iopscience.iop.org/article/10.1088/1757-899X/226/1/012099)\n",
    "- [Predicting Football Results Using Machine Learning Techniques](https://www.imperial.ac.uk/media/imperial-college/faculty-of-engineering/computing/public/1718-ug-projects/Corentin-Herbinet-Using-Machine-Learning-techniques-to-predict-the-outcome-of-profressional-football-matches.pdf)\n",
    "- [Forecasting football match results using a player rating based model](https://www.sciencedirect.com/science/article/pii/S016920702300033X)\n",
    "- [Forecasting football matches by predicting match statistics](https://content.iospress.com/articles/journal-of-sports-analytics/jsa200462)\n",
    "  \n",
    "- Datasets\n",
    "    - https://www.kaggle.com/datasets/hugomathien/soccer\n",
    "    - https://www.football-data.co.uk/ratings.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
